---
# Element Server Suite Community Edition Configuration
# Cluster: sabkhi_lab
# Federation: DISABLED (private mode)

# ALL VALUES MUST BE NESTED UNDER matrix-stack since it's a dependency
matrix-stack:
  # Matrix server name (REQUIRED - used in user IDs: @username:matrix.internal.rmsz005.com)
  serverName: matrix.internal.rmsz005.com

  # Cert-manager configuration for Let's Encrypt
  certManager:
    clusterIssuer: letsencrypt

  # Global ingress configuration
  ingress:
    className: nginx
    annotations:
      nginx.ingress.kubernetes.io/proxy-body-size: "100m"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "600"

  # Synapse - Matrix homeserver
  synapse:
    enabled: true
    
    # Hostname (REQUIRED)
    ingress:
      host: matrix.internal.rmsz005.com
    
    # Media storage
    media:
      storage:
        size: 10Gi
        storageClassName: longhorn-nvme-replicated
        resourcePolicy: keep
      maxUploadSize: 100M
    
    # Resource allocation
    resources:
      requests:
        memory: "1024Mi"
        cpu: "500m"
      limits:
        memory: "2048Mi"
        cpu: "1000m"
    
    # Custom Synapse configuration (homeserver.yaml additions)
    additional:
      0-custom:
        config: |
          # Disable federation
          federation_domain_whitelist: []
          
          # Disable registration
          enable_registration: false
          
          # Presence settings
          presence:
            enabled: true

  # Matrix Authentication Service
  matrixAuthenticationService:
    enabled: true
    
    # Hostname (REQUIRED)
    ingress:
      host: account.internal.rmsz005.com
    
    # Resource allocation
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"
    
    # Custom MAS configuration (config.yaml additions)
    # Email temporarily disabled - will configure after deployment
    # Users can be created via: kubectl exec -it deploy/ess-matrix-authentication-service -- mas-cli manage register-user
    additional: {}

  # Element Web - Matrix client
  elementWeb:
    enabled: true
    
    # Hostname (REQUIRED)
    ingress:
      host: chat.internal.rmsz005.com
    
    # Resource allocation
    resources:
      requests:
        memory: "64Mi"
        cpu: "10m"
      limits:
        memory: "128Mi"
        cpu: "100m"
    
    # Custom Element Web configuration (config.json overrides)
    # Using Tailscale URLs so it works from external browsers
    additional:
      0-tailscale:
        config:
          default_server_config:
            m.homeserver:
              base_url: "https://matrix.taild37df5.ts.net"
              server_name: "matrix.internal.rmsz005.com"

  # Element Admin - Admin interface
  elementAdmin:
    enabled: true
    
    # Hostname (REQUIRED)
    ingress:
      host: admin.internal.rmsz005.com
    
    # Resource allocation
    resources:
      requests:
        memory: "64Mi"
        cpu: "10m"
      limits:
        memory: "128Mi"
        cpu: "100m"

  # Matrix RTC (VOIP/TURN)
  matrixRTC:
    enabled: true
    
    # Hostname (REQUIRED)
    ingress:
      host: mrtc.internal.rmsz005.com

  # PostgreSQL (chart-managed)
  postgres:
    enabled: true
    
    # Storage configuration
    storage:
      size: 5Gi
      storageClassName: longhorn-nvme-replicated
      resourcePolicy: keep

  # HAProxy - Internal load balancer
  # NOTE: HAProxy FD (file descriptor) limits managed by GitOps
  # The chart sets maxconn=40000 which requires ~80k FDs, but system limit is 65535
  # Solution: ess-haproxy-configmap-patch.yaml applies a patched ConfigMap with maxconn=8000
  # This patch is managed by ArgoCD app 'ess-haproxy-patch' (sync wave 1, applies after Helm)
  haproxy:
    replicas: 1
    resources:
      requests:
        memory: "32Mi"
        cpu: "10m"
      limits:
        memory: "64Mi"
        cpu: "100m"

  # Auto-generate secrets (signing keys, etc.)
  initSecrets:
    enabled: true
